# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


"""
Gremlinè¯­æ–™åº“ç”Ÿæˆå™¨ä¸»å…¥å£è„šæœ¬ã€‚

ä»GremlinæŸ¥è¯¢æ¨¡æ¿ç”Ÿæˆå¤§é‡å¤šæ ·åŒ–çš„æŸ¥è¯¢-æè¿°å¯¹ï¼Œç”¨äºText-to-Gremlinä»»åŠ¡çš„è®­ç»ƒæ•°æ®ã€‚
"""

import os
import json
from datetime import datetime
from antlr4 import InputStream, CommonTokenStream
from antlr4.error.ErrorListener import ErrorListener

from .Config import Config
from .Schema import Schema
from .GremlinBase import GremlinBase
from .GremlinParse import Traversal
from .TraversalGenerator import TraversalGenerator
from .GremlinTransVisitor import GremlinTransVisitor

from .gremlin.GremlinLexer import GremlinLexer
from .gremlin.GremlinParser import GremlinParser
import random

class SyntaxErrorListener(ErrorListener):
    """ç§æœ‰é”™è¯¯ç›‘å¬å™¨ç±»ï¼Œæ•è·è¯­æ³•é”™è¯¯ã€‚"""
    
    def __init__(self):
        super().__init__()
        self.has_error = False
        self.error_message = ""
    
    def syntaxError(self, recognizer, offendingSymbol, line, column, msg, e):
        """å½“è¯­æ³•é”™è¯¯å‘ç”Ÿæ—¶ï¼Œæ­¤æ–¹æ³•è¢«è°ƒç”¨ã€‚"""
        self.has_error = True
        self.error_message = f"Syntax Error at line {line}, column {column}: {msg}"

def check_gremlin_syntax(query_string: str) -> tuple[bool, str]:
    """
    æ£€æŸ¥ç»™å®šçš„GremlinæŸ¥è¯¢è¯­å¥çš„è¯­æ³•ã€‚
    
    Args:
        query_string: The Gremlin query to check.
        
    Returns:
        A tuple containing:
        - bool: True if syntax is correct, False otherwise.
        - str: An error message if syntax is incorrect, or "Syntax OK" if correct.
    """
    try:
        input_stream = InputStream(query_string)
        lexer = GremlinLexer(input_stream)
        token_stream = CommonTokenStream(lexer)
        parser = GremlinParser(token_stream)
        
        # ç§»é™¤é»˜è®¤çš„æ§åˆ¶å°é”™è¯¯ç›‘å¬å™¨
        lexer.removeErrorListeners()
        parser.removeErrorListeners()
        
        # æ·»åŠ è‡ªå®šä¹‰çš„ç›‘å¬å™¨
        error_listener = SyntaxErrorListener()
        lexer.addErrorListener(error_listener)
        parser.addErrorListener(error_listener)
        
        # å°è¯•è§£ææŸ¥è¯¢
        parser.queryList()
        
        if error_listener.has_error:
            return (False, error_listener.error_message)
        else:
            return (True, "Syntax OK")
            
    except Exception as e:
        return (False, f"Parser Exception: {str(e)}")

def generate_corpus_from_template(
    template_string: str,
    config: Config,
    schema: Schema,
    gremlin_base: GremlinBase,
    global_corpus_dict: dict
) -> tuple[int, dict]:
    """
    æ‰§è¡Œå•ä¸ª Gremlin æ¨¡æ¿å­—ç¬¦ä¸²çš„å®Œæ•´ pipelineã€‚

    Args:
        template_string: ç”¨ä½œæ¨¡æ¿çš„ Gremlin queryã€‚
        config: åŠ è½½çš„ Config å¯¹è±¡ã€‚
        schema: åŠ è½½çš„ Schema å¯¹è±¡ã€‚
        gremlin_base: åŠ è½½çš„ GremlinBase å¯¹è±¡ã€‚
        global_corpus_dict: ç”¨äºå­˜å‚¨å”¯ä¸€ query-description å¯¹çš„å…¨å±€å­—å…¸ã€‚

    Returns:
        tuple: (æ·»åŠ åˆ°å…¨å±€è¯­æ–™åº“çš„æ–°çš„å”¯ä¸€å¯¹çš„æ•°é‡, å¤„ç†ç»Ÿè®¡ä¿¡æ¯)
    """
    # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'success': False,
        'error_stage': '',
        'error_message': '',
        'generated_count': 0,
        'new_pairs_count': 0,
        'duplicate_count': 0,
        'syntax_error_count': 0
    }

    try:
        # ANTLR è§£æä¸º AST,å¹¶æå–æ¨¡ç‰ˆ
        visitor = GremlinTransVisitor()
        recipe = visitor.parse_and_visit(template_string)
        
        if not recipe:
            stats['error_stage'] = 'recipe_extraction'
            stats['error_message'] = 'Recipe extraction failed'
            return 0, stats
        
        if not hasattr(recipe, 'steps') or not recipe.steps:
            stats['error_stage'] = 'recipe_validation'
            stats['error_message'] = 'Recipe has no steps'
            return 0, stats

        # æ³›åŒ–
        generator = TraversalGenerator(schema, recipe, gremlin_base)
        corpus = generator.generate()
        
        if not corpus:
            stats['error_stage'] = 'generation'
            stats['error_message'] = 'Generator returned empty corpus'
            return 0, stats
        
        stats['generated_count'] = len(corpus)
        
        # è¯­æ³•æ£€æŸ¥ & å…¨å±€å»é‡
        new_pairs_count = 0
        duplicate_count = 0
        syntax_error_count = 0
        
        for query, description in corpus:
            try:
                # å…ˆåˆ¤é‡ï¼Œé¿å…å¯¹é‡å¤é¡¹åšè¯­æ³•æ£€æŸ¥
                if query in global_corpus_dict:
                    duplicate_count += 1
                    continue
                
                # å†è¿›è¡Œè¯­æ³•æ£€æŸ¥
                is_valid, error_msg = check_gremlin_syntax(query)
                
                if not is_valid:
                    syntax_error_count += 1
                    continue
                
                # æ–°çš„æŸ¥è¯¢ä¸”è¯­æ³•æ­£ç¡®ï¼Œæ·»åŠ åˆ°å…¨å±€å­—å…¸
                global_corpus_dict[query] = description
                new_pairs_count += 1
                    
            except Exception as e:
                syntax_error_count += 1
                continue
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats['new_pairs_count'] = new_pairs_count
        stats['duplicate_count'] = duplicate_count
        stats['syntax_error_count'] = syntax_error_count
        stats['success'] = True
        
        # æ·»åŠ ç”Ÿæˆæ•°é‡çš„è­¦å‘Šä¿¡æ¯
        if stats['generated_count'] > 5000:
            stats['warning'] = f'ç”±äºæœ¬æ¡æ¨¡ç‰ˆçš„Recipå¤æ‚,ç”Ÿæˆäº†å¤§é‡æŸ¥è¯¢({stats["generated_count"]}æ¡)'
        elif new_pairs_count == 0 and stats['generated_count'] > 0:
            stats['warning'] = f'ç”Ÿæˆäº†{stats["generated_count"]}æ¡æŸ¥è¯¢ä½†å…¨éƒ¨é‡å¤'
        
        return new_pairs_count, stats
        
    except Exception as e:
        # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸
        stats['error_stage'] = 'unknown'
        stats['error_message'] = str(e)
        return 0, stats


def generate_gremlin_corpus(templates: list[str], 
                           config_path: str, 
                           schema_path: str, 
                           data_path: str,
                           output_file: str = None) -> dict:
    """
    ä»Gremlinæ¨¡æ¿åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„è¯­æ–™åº“ã€‚
    
    æŸ¥è¯¢æ•°é‡ç”± combination_control_config.json ä¸­çš„ max_total_combinations æ§åˆ¶ã€‚
    
    Args:
        templates: GremlinæŸ¥è¯¢æ¨¡æ¿åˆ—è¡¨æˆ–CSVæ–‡ä»¶è·¯å¾„
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        schema_path: Schemaæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        
    Raises:
        FileNotFoundError: å½“å¿…éœ€çš„æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“å‚æ•°æ— æ•ˆæ—¶
    """
    # éªŒè¯å¿…éœ€å‚æ•°
    if not config_path or not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    if not schema_path or not os.path.exists(schema_path):
        raise FileNotFoundError(f"æ¨¡å¼æ–‡ä»¶ä¸å­˜åœ¨: {schema_path}")
    if not data_path or not os.path.exists(data_path):
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
    
    # å¤„ç†æ¨¡æ¿è¾“å…¥
    if isinstance(templates, str) and templates.endswith('.csv'):
        if not os.path.exists(templates):
            raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {templates}")
        # ä»CSVæ–‡ä»¶è¯»å–æ¨¡æ¿
        import csv
        template_list = []
        with open(templates, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if 'gremlin_query' in row:
                    template_list.append(row['gremlin_query'])
                elif 'template' in row:
                    template_list.append(row['template'])
        templates = template_list
    
    if not templates:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡æ¿")
        
    # Load all necessary components once
    config = Config(file_path=config_path)
    schema = Schema(schema_path, data_path)
    gremlin_base = GremlinBase(config)

    # --- Run the generation process for each template with global deduplication ---
    global_corpus_dict = {}  # ä½¿ç”¨å­—å…¸è¿›è¡Œå»é‡ï¼Œkeyæ˜¯queryï¼Œvalueæ˜¯description
    total_new_pairs = 0
    
    # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    processing_stats = {
        'total_templates': len(templates),
        'successful_templates': 0,
        'failed_templates': 0,
        'failed_details': [],
        'total_generated': 0,
        'total_syntax_errors': 0,
        'total_duplicates': 0
    }
    
    print(f"ğŸš€ å¼€å§‹å¤„ç† {len(templates)} ä¸ªæ¨¡æ¿...")
    
    for i, template in enumerate(templates, 1):
        try:
            new_pairs_count, template_stats = generate_corpus_from_template(
                template_string=template,
                config=config,
                schema=schema,
                gremlin_base=gremlin_base,
                global_corpus_dict=global_corpus_dict
            )
            
            total_new_pairs += new_pairs_count
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if template_stats['success']:
                processing_stats['successful_templates'] += 1
                processing_stats['total_generated'] += template_stats['generated_count']
                processing_stats['total_syntax_errors'] += template_stats['syntax_error_count']
                processing_stats['total_duplicates'] += template_stats['duplicate_count']
                
                # æ ¹æ®æƒ…å†µæ˜¾ç¤ºä¸åŒçš„æ¶ˆæ¯
                if new_pairs_count == 0 and template_stats['generated_count'] > 0:
                    print(f"[{i}/{len(templates)}] âš ï¸  ç”Ÿæˆ {template_stats['generated_count']} æ¡æŸ¥è¯¢ä½†å…¨éƒ¨é‡å¤")
                elif template_stats['generated_count'] > 5000:
                    print(f"[{i}/{len(templates)}] âš¡ å¤§é‡ç”Ÿæˆ {new_pairs_count} æ¡æ–°æŸ¥è¯¢ (æ€»ç”Ÿæˆ{template_stats['generated_count']}æ¡)")
                else:
                    print(f"[{i}/{len(templates)}] âœ… æˆåŠŸç”Ÿæˆ {new_pairs_count} æ¡æ–°æŸ¥è¯¢")
            else:
                processing_stats['failed_templates'] += 1
                processing_stats['failed_details'].append({
                    'template_index': i,
                    'template': template[:100] + '...' if len(template) > 100 else template,
                    'error_stage': template_stats['error_stage'],
                    'error_message': template_stats['error_message']
                })
                print(f"[{i}/{len(templates)}] âŒ å¤„ç†å¤±è´¥: {template_stats['error_message']}")
            
        except Exception as e:
            # å¤„ç†å•ä¸ªæ¨¡æ¿æ—¶çš„æ„å¤–é”™è¯¯
            processing_stats['failed_templates'] += 1
            processing_stats['failed_details'].append({
                'template_index': i,
                'template': template[:100] + '...' if len(template) > 100 else template,
                'error_stage': 'unexpected_error',
                'error_message': str(e)
            })
            print(f"[{i}/{len(templates)}] âŒ æ„å¤–é”™è¯¯: {str(e)}")
            continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ¨¡æ¿

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
    full_corpus = [(query, desc) for query, desc in global_corpus_dict.items()]
    
    # --- Save the full corpus to a local file (if output_file is provided) ---
    if output_file:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        out_dir = os.path.dirname(os.path.abspath(output_file))
        if out_dir:
            os.makedirs(out_dir, exist_ok=True)
        
        # ç¡®ä¿åªä¿å­˜æˆåŠŸç”Ÿæˆçš„æŸ¥è¯¢-æè¿°å¯¹
        corpus_data = {
            "metadata": {
                "total_templates": len(templates),
                "successful_templates": processing_stats['successful_templates'],
                "failed_templates": processing_stats['failed_templates'],
                "total_unique_queries": len(full_corpus),
                "generation_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            "corpus": [
                {
                    "query": query,
                    "description": desc
                }
                for query, desc in full_corpus
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(corpus_data, f, ensure_ascii=False, indent=2)

    # --- Generate statistics and display results ---
    stats = _generate_statistics(templates, full_corpus, output_file)
    stats.update({
        "total_templates": len(templates),
        "successful_templates": processing_stats['successful_templates'],
        "failed_templates": processing_stats['failed_templates']
    })
    
    if output_file:
        stats["output_file"] = output_file
    
    _display_final_results(full_corpus, stats)
    
    result = {
        "total_templates": len(templates),
        "successful_templates": processing_stats['successful_templates'],
        "failed_templates": processing_stats['failed_templates'],
        "total_unique_queries": len(full_corpus),
        "statistics": stats,
        "queries": full_corpus
    }
    
    if output_file:
        result["output_file"] = output_file
    
    return result

def _generate_statistics(templates: list, full_corpus: list, output_file: str) -> dict:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    # æŒ‰æŸ¥è¯¢é•¿åº¦åˆ†ç±»ç»Ÿè®¡
    length_stats = {}
    for query, _ in full_corpus:
        steps = query.count('.') 
        length_stats[steps] = length_stats.get(steps, 0) + 1
    
    # æŒ‰æ“ä½œç±»å‹åˆ†ç±»ç»Ÿè®¡
    operation_stats = {
        "æŸ¥è¯¢(V/E)": 0,
        "åˆ›å»º(addV/addE)": 0, 
        "æ›´æ–°(property)": 0,
        "åˆ é™¤(drop)": 0
    }
    
    for query, _ in full_corpus:
        if query.startswith('g.V(') or query.startswith('g.E('):
            if '.drop()' in query:
                operation_stats["åˆ é™¤(drop)"] += 1
            elif '.property(' in query:
                operation_stats["æ›´æ–°(property)"] += 1
            else:
                operation_stats["æŸ¥è¯¢(V/E)"] += 1
        elif '.addV(' in query or '.addE(' in query:
            operation_stats["åˆ›å»º(addV/addE)"] += 1
    
    return {
        "length_stats": length_stats,
        "operation_stats": operation_stats,
        "avg_per_template": len(full_corpus) / len(templates) if templates else 0
    }

def _display_final_results(full_corpus: list, stats: dict):
    """æ˜¾ç¤ºæœ€ç»ˆç”Ÿæˆç»“æœå’Œç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ç”Ÿæˆå®Œæˆç»Ÿè®¡")
    print(f"{'='*50}")
    print(f"å¤„ç†çš„æ¨¡æ¿æ•°é‡: {stats.get('total_templates', 0)}")
    print(f"æˆåŠŸå¤„ç†: {stats.get('successful_templates', 0)}")
    print(f"å¤„ç†å¤±è´¥: {stats.get('failed_templates', 0)}")
    print(f"ç”Ÿæˆçš„ç‹¬ç‰¹æŸ¥è¯¢æ•°é‡: {len(full_corpus)}")
    
    if 'output_file' in stats:
        print(f"è¯­æ–™åº“å·²ä¿å­˜åˆ°: {stats['output_file']}")
    else:
        print(f"è¯­æ–™åº“æœªä¿å­˜åˆ°æ–‡ä»¶ï¼ˆä»…è¿”å›ç»“æœï¼‰")
        
    # æŒ‰æŸ¥è¯¢é•¿åº¦åˆ†ç±»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print("ğŸ“ˆ æŸ¥è¯¢å¤æ‚åº¦åˆ†æ:")
    print(f"{'='*50}")
    
    for steps in sorted(stats['length_stats'].keys()):
        print(f"  {steps}æ­¥æŸ¥è¯¢: {stats['length_stats'][steps]} ä¸ª")
        
    # æŒ‰æ“ä½œç±»å‹åˆ†ç±»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print("ğŸ” æ“ä½œç±»å‹åˆ†æ:")
    print(f"{'='*50}")
    
    for op_type, count in stats['operation_stats'].items():
        percentage = (count / len(full_corpus)) * 100 if full_corpus else 0
        print(f"  {op_type}: {count} ä¸ª ({percentage:.1f}%)")
        
    print(f"\n{'='*50}")
    print(f"âœ… ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(full_corpus)} ä¸ªç‹¬ç‰¹æŸ¥è¯¢")
    print(f"{'='*50}")

