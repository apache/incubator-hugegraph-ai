
"""
Gremlinè¯­æ–™åº“ç”Ÿæˆå™¨ä¸»å…¥å£è„šæœ¬ã€‚

ä»GremlinæŸ¥è¯¢æ¨¡æ¿ç”Ÿæˆå¤§é‡å¤šæ ·åŒ–çš„æŸ¥è¯¢-æè¿°å¯¹ï¼Œç”¨äºText-to-Gremlinä»»åŠ¡çš„è®­ç»ƒæ•°æ®ã€‚
"""

import os
import json
from antlr4 import InputStream, CommonTokenStream
from antlr4.error.ErrorListener import ErrorListener

# Import all our custom modules from the gremlin_base package
from Config import Config
from Schema import Schema
from GremlinBase import GremlinBase
from GremlinParse import Traversal
from TraversalGenerator import TraversalGenerator
from GremlinTransVisitor import GremlinTransVisitor

# Import the ANTLR-generated components
from gremlin.GremlinLexer import GremlinLexer
from gremlin.GremlinParser import GremlinParser
import random

class SyntaxErrorListener(ErrorListener):
    """ç§æœ‰é”™è¯¯ç›‘å¬å™¨ç±»ï¼Œæ•è·è¯­æ³•é”™è¯¯ã€‚"""
    
    def __init__(self):
        super().__init__()
        self.has_error = False
        self.error_message = ""
    
    def syntaxError(self, recognizer, offendingSymbol, line, column, msg, e):
        """å½“è¯­æ³•é”™è¯¯å‘ç”Ÿæ—¶ï¼Œæ­¤æ–¹æ³•è¢«è°ƒç”¨ã€‚"""
        self.has_error = True
        self.error_message = f"Syntax Error at line {line}, column {column}: {msg}"

def check_gremlin_syntax(query_string: str) -> tuple[bool, str]:
    """
    æ£€æŸ¥ç»™å®šçš„GremlinæŸ¥è¯¢è¯­å¥çš„è¯­æ³•ã€‚
    
    Args:
        query_string: The Gremlin query to check.
        
    Returns:
        A tuple containing:
        - bool: True if syntax is correct, False otherwise.
        - str: An error message if syntax is incorrect, or "Syntax OK" if correct.
    """
    try:
        input_stream = InputStream(query_string)
        lexer = GremlinLexer(input_stream)
        token_stream = CommonTokenStream(lexer)
        parser = GremlinParser(token_stream)
        
        # ç§»é™¤é»˜è®¤çš„æ§åˆ¶å°é”™è¯¯ç›‘å¬å™¨
        parser.removeErrorListeners()
        
        # æ·»åŠ è‡ªå®šä¹‰çš„ç›‘å¬å™¨
        error_listener = SyntaxErrorListener()
        parser.addErrorListener(error_listener)
        
        # å°è¯•è§£ææŸ¥è¯¢
        parser.queryList()
        
        if error_listener.has_error:
            return (False, error_listener.error_message)
        else:
            return (True, "Syntax OK")
            
    except Exception as e:
        return (False, f"Parser Exception: {str(e)}")

def generate_corpus_from_template(
    template_string: str,
    config: Config,
    schema: Schema,
    gremlin_base: GremlinBase,
    global_corpus_dict: dict
) -> tuple[int, dict]:
    """
    æ‰§è¡Œå•ä¸ª Gremlin æ¨¡æ¿å­—ç¬¦ä¸²çš„å®Œæ•´ pipelineã€‚

    Args:
        template_string: ç”¨ä½œæ¨¡æ¿çš„ Gremlin queryã€‚
        config: åŠ è½½çš„ Config å¯¹è±¡ã€‚
        schema: åŠ è½½çš„ Schema å¯¹è±¡ã€‚
        gremlin_base: åŠ è½½çš„ GremlinBase å¯¹è±¡ã€‚
        global_corpus_dict: ç”¨äºå­˜å‚¨å”¯ä¸€ query-description å¯¹çš„å…¨å±€å­—å…¸ã€‚

    Returns:
        tuple: (æ·»åŠ åˆ°å…¨å±€è¯­æ–™åº“çš„æ–°çš„å”¯ä¸€å¯¹çš„æ•°é‡, å¤„ç†ç»Ÿè®¡ä¿¡æ¯)
    """
    # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'success': False,
        'error_stage': '',
        'error_message': '',
        'generated_count': 0,
        'new_pairs_count': 0,
        'duplicate_count': 0,
        'syntax_error_count': 0
    }

    try:
        # ANTLR è§£æä¸º AST,å¹¶æå–æ¨¡ç‰ˆ
        visitor = GremlinTransVisitor()
        recipe = visitor.parse_and_visit(template_string)
        
        if not recipe:
            stats['error_stage'] = 'recipe_extraction'
            stats['error_message'] = 'Recipe extraction failed'
            return 0, stats
        
        if not hasattr(recipe, 'steps') or not recipe.steps:
            stats['error_stage'] = 'recipe_validation'
            stats['error_message'] = 'Recipe has no steps'
            return 0, stats

        # æ³›åŒ–
        generator = TraversalGenerator(schema, recipe, gremlin_base)
        corpus = generator.generate()
        
        if not corpus:
            stats['error_stage'] = 'generation'
            stats['error_message'] = 'Generator returned empty corpus'
            return 0, stats
        
        stats['generated_count'] = len(corpus)
        
        # è¯­æ³•æ£€æŸ¥ & å…¨å±€å»é‡
        new_pairs_count = 0
        duplicate_count = 0
        syntax_error_count = 0
        
        for query, description in corpus:
            try:
                # é¦–å…ˆè¿›è¡Œè¯­æ³•æ£€æŸ¥
                is_valid, error_msg = check_gremlin_syntax(query)
                
                if not is_valid:
                    syntax_error_count += 1
                    continue
                    
                if query not in global_corpus_dict:
                    # æ–°çš„æŸ¥è¯¢ä¸”è¯­æ³•æ­£ç¡®ï¼Œæ·»åŠ åˆ°å…¨å±€å­—å…¸
                    global_corpus_dict[query] = description
                    new_pairs_count += 1
                else:
                    # é‡å¤çš„æŸ¥è¯¢ï¼Œè·³è¿‡
                    duplicate_count += 1
                    
            except Exception as e:
                syntax_error_count += 1
                continue
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats['new_pairs_count'] = new_pairs_count
        stats['duplicate_count'] = duplicate_count
        stats['syntax_error_count'] = syntax_error_count
        stats['success'] = True
        
        # æ·»åŠ ç”Ÿæˆæ•°é‡çš„è­¦å‘Šä¿¡æ¯
        if stats['generated_count'] > 5000:
            stats['warning'] = f'ç”±äºæœ¬æ¡æ¨¡ç‰ˆçš„Recipå¤æ‚,ç”Ÿæˆäº†å¤§é‡æŸ¥è¯¢({stats["generated_count"]}æ¡)'
        elif new_pairs_count == 0 and stats['generated_count'] > 0:
            stats['warning'] = f'ç”Ÿæˆäº†{stats["generated_count"]}æ¡æŸ¥è¯¢ä½†å…¨éƒ¨é‡å¤'
        
        return new_pairs_count, stats
        
    except Exception as e:
        # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸
        stats['error_stage'] = 'unknown'
        stats['error_message'] = str(e)
        return 0, stats


def generate_corpus_from_templates(templates: list[str], 
                                  config_path: str = None, 
                                  schema_path: str = None, 
                                  data_path: str = None,
                                  output_file: str = "generated_corpus.json") -> dict:
    """
    ä»Gremlinæ¨¡æ¿åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„è¯­æ–™åº“ã€‚
    
    Args:
        templates: GremlinæŸ¥è¯¢æ¨¡æ¿åˆ—è¡¨
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        schema_path: Schemaæ–‡ä»¶è·¯å¾„  
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶å
        
    Returns:
        åŒ…å«ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    # --- Setup: Define paths and load dependencies ---
    if not config_path or not schema_path or not data_path:
        # è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(current_dir)  # ä»baseç›®å½•å‘ä¸Šä¸€çº§
        
        schema_path = schema_path or os.path.join(project_root, 'db_data', 'schema', 'movie_schema.json')
        data_path = data_path or os.path.join(project_root, 'db_data')
        config_path = config_path or os.path.join(project_root, 'config.json')

    if not all(os.path.exists(p) for p in [config_path, schema_path, data_path]):
        raise FileNotFoundError("Could not find necessary config, schema, or data files.")
        
    # Load all necessary components once
    config = Config(file_path=config_path)
    schema = Schema(schema_path, data_path)
    gremlin_base = GremlinBase(config)

    # --- Run the generation process for each template with global deduplication ---
    global_corpus_dict = {}  # ä½¿ç”¨å­—å…¸è¿›è¡Œå»é‡ï¼Œkeyæ˜¯queryï¼Œvalueæ˜¯description
    total_new_pairs = 0
    
    # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    processing_stats = {
        'total_templates': len(templates),
        'successful_templates': 0,
        'failed_templates': 0,
        'failed_details': [],
        'total_generated': 0,
        'total_syntax_errors': 0,
        'total_duplicates': 0
    }
    
    print(f"ğŸš€ å¼€å§‹å¤„ç† {len(templates)} ä¸ªæ¨¡æ¿...")
    
    for i, template in enumerate(templates, 1):
        try:
            new_pairs_count, template_stats = generate_corpus_from_template(
                template_string=template,
                config=config,
                schema=schema,
                gremlin_base=gremlin_base,
                global_corpus_dict=global_corpus_dict
            )
            
            total_new_pairs += new_pairs_count
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if template_stats['success']:
                processing_stats['successful_templates'] += 1
                processing_stats['total_generated'] += template_stats['generated_count']
                processing_stats['total_syntax_errors'] += template_stats['syntax_error_count']
                processing_stats['total_duplicates'] += template_stats['duplicate_count']
                
                # æ ¹æ®æƒ…å†µæ˜¾ç¤ºä¸åŒçš„æ¶ˆæ¯
                if new_pairs_count == 0 and template_stats['generated_count'] > 0:
                    print(f"[{i}/{len(templates)}] âš ï¸  ç”Ÿæˆ {template_stats['generated_count']} æ¡æŸ¥è¯¢ä½†å…¨éƒ¨é‡å¤")
                elif template_stats['generated_count'] > 5000:
                    print(f"[{i}/{len(templates)}] âš¡ å¤§é‡ç”Ÿæˆ {new_pairs_count} æ¡æ–°æŸ¥è¯¢ (æ€»ç”Ÿæˆ{template_stats['generated_count']}æ¡)")
                else:
                    print(f"[{i}/{len(templates)}] âœ… æˆåŠŸç”Ÿæˆ {new_pairs_count} æ¡æ–°æŸ¥è¯¢")
            else:
                processing_stats['failed_templates'] += 1
                processing_stats['failed_details'].append({
                    'template_index': i,
                    'template': template[:100] + '...' if len(template) > 100 else template,
                    'error_stage': template_stats['error_stage'],
                    'error_message': template_stats['error_message']
                })
                print(f"[{i}/{len(templates)}] âŒ å¤„ç†å¤±è´¥: {template_stats['error_message']}")
            
        except Exception as e:
            # å¤„ç†å•ä¸ªæ¨¡æ¿æ—¶çš„æ„å¤–é”™è¯¯
            processing_stats['failed_templates'] += 1
            processing_stats['failed_details'].append({
                'template_index': i,
                'template': template[:100] + '...' if len(template) > 100 else template,
                'error_stage': 'unexpected_error',
                'error_message': str(e)
            })
            print(f"[{i}/{len(templates)}] âŒ æ„å¤–é”™è¯¯: {str(e)}")
            continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ¨¡æ¿

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
    full_corpus = [(query, desc) for query, desc in global_corpus_dict.items()]
    
    # --- Save the full corpus to a local file ---
    # ç¡®ä¿åªä¿å­˜æˆåŠŸç”Ÿæˆçš„æŸ¥è¯¢-æè¿°å¯¹
    from datetime import datetime
    
    corpus_data = {
        "metadata": {
            "total_templates": len(templates),
            "successful_templates": processing_stats['successful_templates'],
            "failed_templates": processing_stats['failed_templates'],
            "total_unique_queries": len(full_corpus),
            "generation_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "corpus": [
            {
                "query": query,
                "description": desc
            }
            for query, desc in full_corpus
        ]
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(corpus_data, f, ensure_ascii=False, indent=2)

    # --- Generate statistics and display results ---
    stats = _generate_statistics(templates, full_corpus, output_file)
    stats.update({
        "total_templates": len(templates),
        "successful_templates": processing_stats['successful_templates'],
        "failed_templates": processing_stats['failed_templates'],
        "output_file": output_file
    })
    _display_final_results(full_corpus, stats)
    
    return {
        "total_templates": len(templates),
        "successful_templates": processing_stats['successful_templates'],
        "failed_templates": processing_stats['failed_templates'],
        "total_unique_queries": len(full_corpus),
        "output_file": output_file,
        "statistics": stats
    }

def _generate_statistics(templates: list, full_corpus: list, output_file: str) -> dict:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    # æŒ‰æŸ¥è¯¢é•¿åº¦åˆ†ç±»ç»Ÿè®¡
    length_stats = {}
    for query, _ in full_corpus:
        steps = query.count('.') 
        length_stats[steps] = length_stats.get(steps, 0) + 1
    
    # æŒ‰æ“ä½œç±»å‹åˆ†ç±»ç»Ÿè®¡
    operation_stats = {
        "æŸ¥è¯¢(V/E)": 0,
        "åˆ›å»º(addV/addE)": 0, 
        "æ›´æ–°(property)": 0,
        "åˆ é™¤(drop)": 0
    }
    
    for query, _ in full_corpus:
        if query.startswith('g.V(') or query.startswith('g.E('):
            if '.drop()' in query:
                operation_stats["åˆ é™¤(drop)"] += 1
            elif '.property(' in query:
                operation_stats["æ›´æ–°(property)"] += 1
            else:
                operation_stats["æŸ¥è¯¢(V/E)"] += 1
        elif '.addV(' in query or '.addE(' in query:
            operation_stats["åˆ›å»º(addV/addE)"] += 1
    
    return {
        "length_stats": length_stats,
        "operation_stats": operation_stats,
        "avg_per_template": len(full_corpus) / len(templates) if templates else 0
    }

def _display_final_results(full_corpus: list, stats: dict):
    """æ˜¾ç¤ºæœ€ç»ˆç”Ÿæˆç»“æœå’Œç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ç”Ÿæˆå®Œæˆç»Ÿè®¡")
    print(f"{'='*50}")
    print(f"å¤„ç†çš„æ¨¡æ¿æ•°é‡: {stats.get('total_templates', 0)}")
    print(f"æˆåŠŸå¤„ç†: {stats.get('successful_templates', 0)}")
    print(f"å¤„ç†å¤±è´¥: {stats.get('failed_templates', 0)}")
    print(f"ç”Ÿæˆçš„ç‹¬ç‰¹æŸ¥è¯¢æ•°é‡: {len(full_corpus)}")
    print(f"è¯­æ–™åº“å·²ä¿å­˜åˆ°: {stats.get('output_file', 'generated_corpus.json')}")
        
    # æŒ‰æŸ¥è¯¢é•¿åº¦åˆ†ç±»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print("ğŸ“ˆ æŸ¥è¯¢å¤æ‚åº¦åˆ†æ:")
    print(f"{'='*50}")
    
    for steps in sorted(stats['length_stats'].keys()):
        print(f"  {steps}æ­¥æŸ¥è¯¢: {stats['length_stats'][steps]} ä¸ª")
        
    # æŒ‰æ“ä½œç±»å‹åˆ†ç±»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print("ğŸ” æ“ä½œç±»å‹åˆ†æ:")
    print(f"{'='*50}")
    
    for op_type, count in stats['operation_stats'].items():
        percentage = (count / len(full_corpus)) * 100 if full_corpus else 0
        print(f"  {op_type}: {count} ä¸ª ({percentage:.1f}%)")
        
    print(f"\n{'='*50}")
    print(f"âœ… ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(full_corpus)} ä¸ªç‹¬ç‰¹æŸ¥è¯¢")
    print(f"{'='*50}")



if __name__ == '__main__':
    # templates = [
    #     # === æŸ¥è¯¢æ“ä½œ (Query) - 40% ===
        
    #     # åŸºç¡€æŸ¥è¯¢
    #     "g.V().has('name', 'John')",
    #     "g.V().has('title', 'The Matrix')",
    #     "g.V().has('born', 1961)",
    #     "g.V().hasLabel('person')",
    #     "g.V().hasLabel('movie')",
        
    #     # å¯¼èˆªæŸ¥è¯¢
    #     "g.V().has('name', 'Laurence Fishburne').out('acted_in')",
    #     "g.V().has('title', 'The Matrix').in('acted_in')",
    #     "g.V().hasLabel('person').out('directed')",
    #     "g.V().hasLabel('movie').in('rate')",
        
    #     # å¤æ‚æŸ¥è¯¢
    #     "g.V().has('name', 'Laurence Fishburne').out('acted_in').has('title', 'The Matrix')",
    #     "g.V().hasLabel('person').out('acted_in').in('rate')",
    #     "g.V().has('title', 'Matrix').in('acted_in').out('directed')",
        
    #     # === åˆ›å»ºæ“ä½œ (Create) - 25% ===
        
    #     # åŸºç¡€åˆ›å»º
    #     "g.addV('person')",
    #     "g.addV('movie')",
    #     "g.addV('user')",
        
    #     # å¸¦å±æ€§åˆ›å»º
    #     "g.addV('person').property('name', 'New Actor')",
    #     "g.addV('movie').property('title', 'New Movie')",
    #     "g.addV('person').property('name', 'Jane').property('born', 1990)",
    #     "g.addV('movie').property('title', 'Test Movie').property('duration', 120)",
    #     "g.addV('user').property('login', 'newuser').property('name', 'New User')",
        
    #     # === æ›´æ–°æ“ä½œ (Update) - 25% ===
        
    #     # å•å±æ€§æ›´æ–°
    #     "g.V().has('name', 'John').property('born', 1990)",
    #     "g.V().has('title', 'Test').property('duration', 120)",
    #     "g.V().hasLabel('person').has('name', 'Jane').property('born', 1985)",
    #     "g.V().hasLabel('movie').has('title', 'Old Movie').property('rated', 'PG-13')",
        
    #     # å¤šå±æ€§æ›´æ–°
    #     "g.V().has('name', 'John').property('born', 1990).property('poster_image', 'new_url')",
    #     "g.V().has('title', 'Test').property('duration', 150).property('rated', 'R')",
    #     "g.V().hasLabel('user').has('login', 'testuser').property('name', 'Updated Name').property('born', 1995)",
        
    #     # === åˆ é™¤æ“ä½œ (Delete) - 10% ===
        
    #     # åŸºç¡€åˆ é™¤
    #     "g.V().has('name', 'temp_person').drop()",
    #     "g.V().has('title', 'temp_movie').drop()",
    #     "g.V().hasLabel('user').has('login', 'temp_user').drop()",
        
    #     # æ¡ä»¶åˆ é™¤
    #     "g.V().hasLabel('person').has('born', 0).drop()",
    #     "g.V().hasLabel('movie').has('duration', 0).drop()",
    # ]
    
    def load_templates_from_csv(csv_file_path: str) -> tuple[list[str], dict]:
        """
        ä»CSVæ–‡ä»¶ä¸­åŠ è½½GremlinæŸ¥è¯¢ä½œä¸ºæ¨¡æ¿
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            
        Returns:
            tuple: (æˆåŠŸåŠ è½½çš„æŸ¥è¯¢åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
        """
        import csv
        
        templates = []
        stats = {
            'total_rows': 0,
            'successful_loads': 0,
            'failed_loads': 0,
            'failed_queries': []
        }
        
        try:
            with open(csv_file_path, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                
                for row_num, row in enumerate(reader, 1):
                    stats['total_rows'] += 1
                    
                    try:
                        # è·å–gremlin_queryåˆ—
                        gremlin_query = row.get('gremlin_query', '').strip()
                        
                        if not gremlin_query:
                            stats['failed_loads'] += 1
                            stats['failed_queries'].append(f"ç¬¬{row_num}è¡Œ: ç©ºæŸ¥è¯¢")
                            continue
                        
                        # ç§»é™¤å¯èƒ½çš„å¼•å·åŒ…å›´
                        if gremlin_query.startswith('"') and gremlin_query.endswith('"'):
                            gremlin_query = gremlin_query[1:-1]
                        
                        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
                        if not gremlin_query.startswith('g.'):
                            stats['failed_loads'] += 1
                            stats['failed_queries'].append(f"ç¬¬{row_num}è¡Œ: æ ¼å¼é”™è¯¯")
                            continue
                        
                        templates.append(gremlin_query)
                        stats['successful_loads'] += 1
                            
                    except Exception as e:
                        stats['failed_loads'] += 1
                        stats['failed_queries'].append(f"ç¬¬{row_num}è¡Œ: {str(e)}")
                        continue
                        
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°CSVæ–‡ä»¶: {csv_file_path}")
            return [], stats
        except Exception as e:
            print(f"âŒ è¯»å–CSVæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return [], stats
        
        return templates, stats
    
    # ä»CSVæ–‡ä»¶åŠ è½½æ¨¡æ¿
    csv_file_path = "cypher2gremlin_dataset.csv"
    
    print(f"ğŸ”„ ä» {csv_file_path} åŠ è½½GremlinæŸ¥è¯¢æ¨¡æ¿...")
    templates, load_stats = load_templates_from_csv(csv_file_path)
    
    print(f"ğŸ“Š CSVåŠ è½½ç»Ÿè®¡: {load_stats['successful_loads']}/{load_stats['total_rows']} æˆåŠŸ")
    
    if load_stats['failed_loads'] > 0:
        print(f"âš ï¸  {load_stats['failed_loads']} ä¸ªæ¨¡æ¿åŠ è½½å¤±è´¥")
    
    if not templates:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡æ¿ï¼Œç¨‹åºé€€å‡º")
        exit(1)
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(templates)} ä¸ªæ¨¡æ¿ï¼Œå¼€å§‹ç”Ÿæˆè¯­æ–™åº“...")
    
    # ç”Ÿæˆè¯­æ–™åº“
    try:
        result = generate_corpus_from_templates(templates)
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()