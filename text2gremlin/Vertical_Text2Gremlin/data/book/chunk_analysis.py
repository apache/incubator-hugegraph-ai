import json

def analyze_word_count(file_path):
    """
    åˆ†ægremlin_book_chunks.jsonæ–‡ä»¶ä¸­çš„word_countç»Ÿè®¡ä¿¡æ¯
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"æˆåŠŸåŠ è½½æ–‡ä»¶ï¼Œå…± {len(data)} æ¡è®°å½•")

        max_word_count = 0  # chunkæœ€å¤§å­—ç¬¦æ•°
        total_word_count = 0  # æ€»å­—ç¬¦æ•°
        ranges = {
            "1-100": 0,
            "100-300": 0,
            "300-500": 0,
            "500-800": 0,
            "800-1000": 0,
            "1000-1500": 0,
            "1500-2000": 0,
            "2000+": 0
        }
        
        for item in data:
            if 'metadata' in item and 'word_count' in item['metadata']:
                wc = item['metadata']['word_count']
                max_word_count = max(max_word_count, wc)
                total_word_count += wc  
                
                # åŒºé—´ç»Ÿè®¡
                if 1 <= wc < 100:
                    ranges["1-100"] += 1
                elif 100 <= wc < 300:
                    ranges["100-300"] += 1
                elif 300 <= wc < 500:
                    ranges["300-500"] += 1
                elif 500 <= wc < 800:
                    ranges["500-800"] += 1
                elif 800 <= wc < 1000:
                    ranges["800-1000"] += 1
                elif 1000 <= wc < 1500:
                    ranges["1000-1500"] += 1
                elif 1500 <= wc < 2000:
                    ranges["1500-2000"] += 1
                elif wc >= 2000:
                    ranges["2000+"] += 1
            else:
                print("è­¦å‘Š: å‘ç°ç¼ºå°‘metadataæˆ–word_countçš„è®°å½•")
        
        print("\n" + "="*50)
        print("ç»Ÿè®¡åˆ†æç»“æœ")
        print("="*50)
        print(f"æœ€å¤§ word_count: {max_word_count}")
        print(f"æ€»å­—ç¬¦æ•°: {total_word_count:,}")  
        print(f"å¹³å‡æ¯æ®µå­—æ•°: {total_word_count/len(data):.1f}")
        
        print("\nåŒºé—´ç»Ÿè®¡:")
        print("-" * 30)
        
        total_count = 0
        for range_name, count in ranges.items():
            print(f"  {range_name:12}: {count:4} æ¡")
            total_count += count
        
        print("-" * 30)
        print(f"  {'æ€»è®¡':12}: {total_count:4} æ¡")
        
        return max_word_count, total_word_count, ranges
        
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return None, None, None
    except json.JSONDecodeError:
        print(f"é”™è¯¯: æ–‡ä»¶ {file_path} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
        return None, None, None
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        return None, None, None

def save_results_to_file(max_count, total_count, ranges, output_file="word_count_analysis.txt"):
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("Gremlin Book Word Count åˆ†æç»“æœ\n")
            f.write("="*50 + "\n")
            f.write(f"æœ€å¤§ word_count: {max_count}\n")
            f.write(f"æ€»å­—ç¬¦æ•°: {total_count:,}\n")
            f.write(f"å¹³å‡æ¯æ®µå­—æ•°: {total_count/sum(ranges.values()):.1f}\n\n")
            f.write("åŒºé—´ç»Ÿè®¡:\n")
            f.write("-" * 30 + "\n")
            for range_name, count in ranges.items():
                f.write(f"{range_name:12}: {count:4} æ¡\n")
            
            total = sum(ranges.values())
            f.write("-" * 30 + "\n")
            f.write(f"{'æ€»è®¡':12}: {total:4} æ¡\n")
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ° {output_file}")
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    max_count, total_count, ranges = analyze_word_count("gremlin_book_chunks.json")
    
    if max_count is not None and total_count is not None and ranges is not None:
        save_results_to_file(max_count, total_count, ranges)

        print(f"\nğŸ“Š é¢å¤–ç»Ÿè®¡ä¿¡æ¯:")
        if sum(ranges.values()) > 0:
            avg_chars = total_count / sum(ranges.values())
            print(f"   å¹³å‡æ¯æ®µå­—æ•°: {avg_chars:.1f}")